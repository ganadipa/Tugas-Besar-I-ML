{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "os.chdir(\"../..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import custom FFNN implementation\n",
    "import os\n",
    "import sys\n",
    "# Add the parent directory to path to import your modules\n",
    "sys.path.append(os.path.dirname(os.path.dirname(os.getcwd())))\n",
    "\n",
    "from lib.neural import NeuralNetwork, NetworkLayer\n",
    "from lib.ffnn import FFNN\n",
    "from lib.activation import ReLU, Sigmoid, Tanh, Linear, Softmax\n",
    "from lib.loss import MSE, BCE, CCE\n",
    "from lib.weight_initializer import ZeroInitializer, UniformInitializer, NormalInitializer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Loading data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sparsity with L1 penalty: 79.73%\n",
      "Test score with L1 penalty: 0.8382\n",
      "Example run in 5.132 s\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 10 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Authors: The scikit-learn developers\n",
    "# SPDX-License-Identifier: BSD-3-Clause\n",
    "\n",
    "import time\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.utils import check_random_state\n",
    "import logging\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "# Turn down for faster convergence\n",
    "t0 = time.time()\n",
    "train_samples = 5000\n",
    "\n",
    "# Load data from https://www.openml.org/d/554\n",
    "logging.info(\"Loading data\")\n",
    "X, y = fetch_openml(\"mnist_784\", version=1, return_X_y=True, as_frame=False)\n",
    "\n",
    "random_state = check_random_state(0)\n",
    "permutation = random_state.permutation(X.shape[0])\n",
    "X = X[permutation]\n",
    "y = y[permutation]\n",
    "X = X.reshape((X.shape[0], -1))\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, train_size=train_samples, test_size=10000\n",
    ")\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Turn up tolerance for faster convergence\n",
    "clf = LogisticRegression(C=50.0 / train_samples, penalty=\"l1\", solver=\"saga\", tol=0.1)\n",
    "clf.fit(X_train, y_train)\n",
    "sparsity = np.mean(clf.coef_ == 0) * 100\n",
    "score = clf.score(X_test, y_test)\n",
    "# print('Best C % .4f' % clf.C_)\n",
    "print(\"Sparsity with L1 penalty: %.2f%%\" % sparsity)\n",
    "print(\"Test score with L1 penalty: %.4f\" % score)\n",
    "\n",
    "coef = clf.coef_.copy()\n",
    "plt.figure(figsize=(10, 5))\n",
    "scale = np.abs(coef).max()\n",
    "for i in range(10):\n",
    "    l1_plot = plt.subplot(2, 5, i + 1)\n",
    "    l1_plot.imshow(\n",
    "        coef[i].reshape(28, 28),\n",
    "        interpolation=\"nearest\",\n",
    "        cmap=plt.cm.RdBu,\n",
    "        vmin=-scale,\n",
    "        vmax=scale,\n",
    "    )\n",
    "    l1_plot.set_xticks(())\n",
    "    l1_plot.set_yticks(())\n",
    "    l1_plot.set_xlabel(\"Class %i\" % i)\n",
    "plt.suptitle(\"Classification vector for...\")\n",
    "\n",
    "run_time = time.time() - t0\n",
    "print(\"Example run in %.3f s\" % run_time)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set: 4000 samples\n",
      "Validation set: 1000 samples\n",
      "Test set: 10000 samples\n",
      "Input features: 784\n",
      "Output classes: 10\n"
     ]
    }
   ],
   "source": [
    "# Preprocess data for FFNN\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# Load data (using your already loaded data)\n",
    "# X_train and X_test are already loaded and scaled\n",
    "\n",
    "# Convert labels to one-hot encoding for neural network\n",
    "encoder = OneHotEncoder(sparse_output=False)\n",
    "y_train_onehot = encoder.fit_transform(y_train.reshape(-1, 1))\n",
    "y_test_onehot = encoder.transform(y_test.reshape(-1, 1))\n",
    "\n",
    "# Create validation set\n",
    "X_train_ffnn, X_val, y_train_ffnn, y_val = train_test_split(\n",
    "    X_train, y_train_onehot, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "print(f\"Training set: {X_train_ffnn.shape[0]} samples\")\n",
    "print(f\"Validation set: {X_val.shape[0]} samples\")\n",
    "print(f\"Test set: {X_test.shape[0]} samples\")\n",
    "print(f\"Input features: {X_train.shape[1]}\")\n",
    "print(f\"Output classes: {y_train_onehot.shape[1]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions for evaluation and visualization\n",
    "def evaluate_model(model, X, y_onehot):\n",
    "    \"\"\"Evaluate model accuracy on given data.\"\"\"\n",
    "    predictions = model.predict(X)\n",
    "    predicted_classes = np.argmax(predictions, axis=1)\n",
    "    true_classes = np.argmax(y_onehot, axis=1)\n",
    "    accuracy = np.mean(predicted_classes == true_classes)\n",
    "    return accuracy\n",
    "\n",
    "def plot_train_history(history, title=\"Training History\"):\n",
    "    \"\"\"Plot training and validation loss history.\"\"\"\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(history['train_loss'], label='Training Loss')\n",
    "    if 'val_loss' in history and history['val_loss']:\n",
    "        plt.plot(history['val_loss'], label='Validation Loss')\n",
    "    plt.title(title)\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing width variations...\n",
      "\n",
      "Width Variation 1: [784, 32, 10]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/5:   0%|          | 0/125 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "non-broadcastable output operand with shape (32,32) doesn't match the broadcast shape (32,32,32)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 47\u001b[0m\n\u001b[1;32m     44\u001b[0m model \u001b[38;5;241m=\u001b[39m FFNN(network)\n\u001b[1;32m     46\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[0;32m---> 47\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     48\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_train_ffnn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train_ffnn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     49\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbase_config\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mbatch_size\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     50\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbase_config\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mepochs\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     51\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mX_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_val\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     52\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbase_config\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlearning_rate\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     53\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\n\u001b[1;32m     54\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;66;03m# Store results\u001b[39;00m\n\u001b[1;32m     57\u001b[0m width_histories\u001b[38;5;241m.\u001b[39mappend(history)\n",
      "File \u001b[0;32m~/code/kuliah/sem6/Machine-learning/tubes-1/src/lib/ffnn.py:285\u001b[0m, in \u001b[0;36mFFNN.fit\u001b[0;34m(self, x_train, y_train, batch_size, epochs, validation_data, learning_rate, verbose)\u001b[0m\n\u001b[1;32m    282\u001b[0m batch_y \u001b[38;5;241m=\u001b[39m y_shuffled[start_idx:end_idx]\n\u001b[1;32m    284\u001b[0m \u001b[38;5;66;03m# Forward and backward passes\u001b[39;00m\n\u001b[0;32m--> 285\u001b[0m batch_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mback_prop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_x\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_y\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    287\u001b[0m \u001b[38;5;66;03m# Update weights\u001b[39;00m\n\u001b[1;32m    288\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mupdate_weights(learning_rate)\n",
      "File \u001b[0;32m~/code/kuliah/sem6/Machine-learning/tubes-1/src/lib/ffnn.py:172\u001b[0m, in \u001b[0;36mFFNN.back_prop\u001b[0;34m(self, x_batch, y_batch)\u001b[0m\n\u001b[1;32m    166\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m l \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    167\u001b[0m         \u001b[38;5;66;03m# Compute delta for previous layer\u001b[39;00m\n\u001b[1;32m    168\u001b[0m         \u001b[38;5;66;03m# delta shape: (current_layer_size, batch_size)\u001b[39;00m\n\u001b[1;32m    169\u001b[0m         \u001b[38;5;66;03m# weights shape: (current_layer_size, prev_layer_size)\u001b[39;00m\n\u001b[1;32m    170\u001b[0m         \u001b[38;5;66;03m# new delta shape: (prev_layer_size, batch_size)\u001b[39;00m\n\u001b[1;32m    171\u001b[0m         delta \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mdot(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnetwork\u001b[38;5;241m.\u001b[39mweights[l\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mT, delta)\n\u001b[0;32m--> 172\u001b[0m         delta \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m=\u001b[39m prev_layer\u001b[38;5;241m.\u001b[39mactivation\u001b[38;5;241m.\u001b[39mderivative(prev_layer\u001b[38;5;241m.\u001b[39mnodes)\n\u001b[1;32m    174\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\n",
      "\u001b[0;31mValueError\u001b[0m: non-broadcastable output operand with shape (32,32) doesn't match the broadcast shape (32,32,32)"
     ]
    }
   ],
   "source": [
    "base_config = {\n",
    "    'learning_rate': 0.01,\n",
    "    'batch_size': 32,\n",
    "    'epochs': 5,  \n",
    "    'loss_function': CCE(),\n",
    "    'activation': Softmax(),\n",
    "    'initializer': NormalInitializer(seed=42)\n",
    "}\n",
    "\n",
    "# Define different architectures for width variation (fixed depth)\n",
    "width_variations = [\n",
    "    [784, 32, 10],         # Narrow\n",
    "    [784, 128, 10],        # Medium\n",
    "    [784, 512, 10]         # Wide\n",
    "]\n",
    "\n",
    "# Define different architectures for depth variation (fixed width)\n",
    "depth_variations = [\n",
    "    [784, 64, 10],               # Shallow (1 hidden layer)\n",
    "    [784, 64, 64, 10],           # Medium (2 hidden layers)\n",
    "    [784, 64, 64, 64, 10]        # Deep (3 hidden layers)\n",
    "]\n",
    "\n",
    "# Test width variations\n",
    "width_histories = []\n",
    "width_accuracies = []\n",
    "\n",
    "print(\"Testing width variations...\")\n",
    "for i, architecture in enumerate(width_variations):\n",
    "    print(f\"\\nWidth Variation {i+1}: {architecture}\")\n",
    "    \n",
    "    # Create activations list (output layer uses Softmax)\n",
    "    activations = [base_config['activation']] * (len(architecture) - 2) + [Softmax()]\n",
    "    \n",
    "    # Create neural network\n",
    "    network = NeuralNetwork(\n",
    "        node_counts=architecture,\n",
    "        activations=activations,\n",
    "        loss_function=base_config['loss_function'],\n",
    "        initialize_method=base_config['initializer']\n",
    "    )\n",
    "    \n",
    "    # Create FFNN model\n",
    "    model = FFNN(network)\n",
    "    \n",
    "    # Train the model\n",
    "    history = model.fit(\n",
    "        X_train_ffnn, y_train_ffnn,\n",
    "        batch_size=base_config['batch_size'],\n",
    "        epochs=base_config['epochs'],\n",
    "        validation_data=(X_val, y_val),\n",
    "        learning_rate=base_config['learning_rate'],\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    # Store results\n",
    "    width_histories.append(history)\n",
    "    \n",
    "    # Evaluate on test set\n",
    "    accuracy = evaluate_model(model, X_test, y_test_onehot)\n",
    "    width_accuracies.append(accuracy)\n",
    "    print(f\"Test accuracy: {accuracy:.4f}\")\n",
    "\n",
    "# Plot results for width variations\n",
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "# Plot width variation loss\n",
    "plt.subplot(1, 2, 1)\n",
    "for i, history in enumerate(width_histories):\n",
    "    plt.plot(history['train_loss'], label=f\"Width {width_variations[i][1]}\")\n",
    "plt.title('Training Loss vs Width')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Compare test accuracies for width\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.bar([str(arch[1]) for arch in width_variations], width_accuracies)\n",
    "plt.title('Test Accuracy vs Width')\n",
    "plt.xlabel('Hidden Layer Width')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim(0, 1)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Test depth variations\n",
    "depth_histories = []\n",
    "depth_accuracies = []\n",
    "\n",
    "print(\"\\nTesting depth variations...\")\n",
    "for i, architecture in enumerate(depth_variations):\n",
    "    print(f\"\\nDepth Variation {i+1}: {architecture}\")\n",
    "    \n",
    "    # Create activations list (output layer uses Softmax)\n",
    "    activations = [base_config['activation']] * (len(architecture) - 2) + [Softmax()]\n",
    "    \n",
    "    # Create neural network\n",
    "    network = NeuralNetwork(\n",
    "        node_counts=architecture,\n",
    "        activations=activations,\n",
    "        loss_function=base_config['loss_function'],\n",
    "        initialize_method=base_config['initializer']\n",
    "    )\n",
    "    \n",
    "    # Create FFNN model\n",
    "    model = FFNN(network, learning_rate=base_config['learning_rate'])\n",
    "    \n",
    "    # Train the model\n",
    "    history = model.fit(\n",
    "        X_train_ffnn, y_train_ffnn,\n",
    "        batch_size=base_config['batch_size'],\n",
    "        epochs=base_config['epochs'],\n",
    "        validation_data=(X_val, y_val),\n",
    "        learning_rate=base_config['learning_rate'],\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    # Store results\n",
    "    depth_histories.append(history)\n",
    "    \n",
    "    # Evaluate on test set\n",
    "    accuracy = evaluate_model(model, X_test, y_test_onehot)\n",
    "    depth_accuracies.append(accuracy)\n",
    "    print(f\"Test accuracy: {accuracy:.4f}\")\n",
    "\n",
    "# Plot results for depth variations\n",
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "# Plot depth variation loss\n",
    "plt.subplot(1, 2, 1)\n",
    "for i, history in enumerate(depth_histories):\n",
    "    plt.plot(history['train_loss'], label=f\"Depth {len(depth_variations[i]) - 2}\")\n",
    "plt.title('Training Loss vs Depth')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Compare test accuracies for depth\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.bar([str(len(arch) - 2) for arch in depth_variations], depth_accuracies)\n",
    "plt.title('Test Accuracy vs Depth')\n",
    "plt.xlabel('Number of Hidden Layers')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim(0, 1)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define base architecture\n",
    "architecture = [784, 128, 10]\n",
    "\n",
    "# Define activation functions to test (for hidden layers)\n",
    "activation_functions = [Linear, ReLU, Sigmoid, Tanh]\n",
    "\n",
    "# Test different activation functions\n",
    "activation_histories = []\n",
    "activation_accuracies = []\n",
    "activation_models = []\n",
    "\n",
    "print(\"Testing activation functions...\")\n",
    "for activation in activation_functions:\n",
    "    print(f\"\\nActivation: {activation.__name__}\")\n",
    "    \n",
    "    # Create activations list (output layer uses Softmax)\n",
    "    activations = [activation] + [Softmax]\n",
    "    \n",
    "    # Create neural network\n",
    "    network = NeuralNetwork(\n",
    "        node_counts=architecture,\n",
    "        activations=activations,\n",
    "        loss_function=base_config['loss_function'],\n",
    "        initialize_method=base_config['initializer']\n",
    "    )\n",
    "    \n",
    "    # Create FFNN model\n",
    "    model = FFNN(network, learning_rate=base_config['learning_rate'])\n",
    "    \n",
    "    # Train the model\n",
    "    history = model.fit(\n",
    "        X_train_ffnn, y_train_ffnn,\n",
    "        batch_size=base_config['batch_size'],\n",
    "        epochs=base_config['epochs'],\n",
    "        validation_data=(X_val, y_val),\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    # Store results\n",
    "    activation_histories.append(history)\n",
    "    activation_models.append(model)\n",
    "    \n",
    "    # Evaluate on test set\n",
    "    accuracy = evaluate_model(model, X_test, y_test_onehot)\n",
    "    activation_accuracies.append(accuracy)\n",
    "    print(f\"Test accuracy: {accuracy:.4f}\")\n",
    "\n",
    "# Plot training loss\n",
    "plt.figure(figsize=(10, 5))\n",
    "for i, history in enumerate(activation_histories):\n",
    "    plt.plot(history['train_loss'], label=f\"{activation_functions[i].__name__}\")\n",
    "plt.title('Training Loss vs Activation Function')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()\n",
    "\n",
    "# Compare test accuracies\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.bar([act.__name__ for act in activation_functions], activation_accuracies)\n",
    "plt.title('Test Accuracy vs Activation Function')\n",
    "plt.xlabel('Activation Function')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim(0, 1)\n",
    "plt.show()\n",
    "\n",
    "# Plot weight distributions\n",
    "plt.figure(figsize=(15, 5))\n",
    "for i, model in enumerate(activation_models):\n",
    "    plt.subplot(1, len(activation_models), i+1)\n",
    "    weights = model.network.weights[0].flatten()\n",
    "    plt.hist(weights, bins=30, alpha=0.7)\n",
    "    plt.title(f\"{activation_functions[i].__name__} Weights\")\n",
    "    plt.xlabel(\"Weight Value\")\n",
    "    plt.ylabel(\"Frequency\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Plot gradient distributions\n",
    "plt.figure(figsize=(15, 5))\n",
    "for i, model in enumerate(activation_models):\n",
    "    plt.subplot(1, len(activation_models), i+1)\n",
    "    gradients = model.network.gradients[0].flatten()\n",
    "    plt.hist(gradients, bins=30, alpha=0.7)\n",
    "    plt.title(f\"{activation_functions[i].__name__} Gradients\")\n",
    "    plt.xlabel(\"Gradient Value\")\n",
    "    plt.ylabel(\"Frequency\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define base architecture\n",
    "architecture = [784, 128, 10]\n",
    "\n",
    "# Define learning rates to test\n",
    "learning_rates = [0.001, 0.01, 0.1]\n",
    "\n",
    "# Test different learning rates\n",
    "lr_histories = []\n",
    "lr_accuracies = []\n",
    "lr_models = []\n",
    "\n",
    "print(\"Testing learning rates...\")\n",
    "for lr in learning_rates:\n",
    "    print(f\"\\nLearning Rate: {lr}\")\n",
    "    \n",
    "    # Create activations list (output layer uses Softmax)\n",
    "    activations = [ReLU] + [Softmax]\n",
    "    \n",
    "    # Create neural network\n",
    "    network = NeuralNetwork(\n",
    "        node_counts=architecture,\n",
    "        activations=activations,\n",
    "        loss_function=base_config['loss_function'],\n",
    "        initialize_method=base_config['initializer']\n",
    "    )\n",
    "    \n",
    "    # Create FFNN model\n",
    "    model = FFNN(network, learning_rate=lr)\n",
    "    \n",
    "    # Train the model\n",
    "    history = model.fit(\n",
    "        X_train_ffnn, y_train_ffnn,\n",
    "        batch_size=base_config['batch_size'],\n",
    "        epochs=base_config['epochs'],\n",
    "        validation_data=(X_val, y_val),\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    # Store results\n",
    "    lr_histories.append(history)\n",
    "    lr_models.append(model)\n",
    "    \n",
    "    # Evaluate on test set\n",
    "    accuracy = evaluate_model(model, X_test, y_test_onehot)\n",
    "    lr_accuracies.append(accuracy)\n",
    "    print(f\"Test accuracy: {accuracy:.4f}\")\n",
    "\n",
    "# Plot training loss\n",
    "plt.figure(figsize=(10, 5))\n",
    "for i, history in enumerate(lr_histories):\n",
    "    plt.plot(history['train_loss'], label=f\"LR = {learning_rates[i]}\")\n",
    "plt.title('Training Loss vs Learning Rate')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()\n",
    "\n",
    "# Compare test accuracies\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.bar([str(lr) for lr in learning_rates], lr_accuracies)\n",
    "plt.title('Test Accuracy vs Learning Rate')\n",
    "plt.xlabel('Learning Rate')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim(0, 1)\n",
    "plt.show()\n",
    "\n",
    "# Plot weight distributions\n",
    "plt.figure(figsize=(15, 5))\n",
    "for i, model in enumerate(lr_models):\n",
    "    plt.subplot(1, len(lr_models), i+1)\n",
    "    weights = model.network.weights[0].flatten()\n",
    "    plt.hist(weights, bins=30, alpha=0.7)\n",
    "    plt.title(f\"LR = {learning_rates[i]} Weights\")\n",
    "    plt.xlabel(\"Weight Value\")\n",
    "    plt.ylabel(\"Frequency\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Plot gradient distributions\n",
    "plt.figure(figsize=(15, 5))\n",
    "for i, model in enumerate(lr_models):\n",
    "    plt.subplot(1, len(lr_models), i+1)\n",
    "    gradients = model.network.gradients[0].flatten()\n",
    "    plt.hist(gradients, bins=30, alpha=0.7)\n",
    "    plt.title(f\"LR = {learning_rates[i]} Gradients\")\n",
    "    plt.xlabel(\"Gradient Value\")\n",
    "    plt.ylabel(\"Frequency\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define base architecture\n",
    "architecture = [784, 128, 10]\n",
    "\n",
    "# Define initializers to test\n",
    "initializers = [\n",
    "    ZeroInitializer(),\n",
    "    UniformInitializer(low=-0.1, high=0.1, seed=42),\n",
    "    NormalInitializer(mean=0, var=0.1, seed=42)\n",
    "]\n",
    "initializer_names = [\"Zero\", \"Uniform\", \"Normal\"]\n",
    "\n",
    "# Test different initializers\n",
    "init_histories = []\n",
    "init_accuracies = []\n",
    "init_models = []\n",
    "\n",
    "print(\"Testing weight initializers...\")\n",
    "for i, initializer in enumerate(initializers):\n",
    "    print(f\"\\nInitializer: {initializer_names[i]}\")\n",
    "    \n",
    "    # Create activations list (output layer uses Softmax)\n",
    "    activations = [ReLU] + [Softmax]\n",
    "    \n",
    "    # Create neural network\n",
    "    network = NeuralNetwork(\n",
    "        node_counts=architecture,\n",
    "        activations=activations,\n",
    "        loss_function=base_config['loss_function'],\n",
    "        initialize_method=initializer\n",
    "    )\n",
    "    \n",
    "    # Create FFNN model\n",
    "    model = FFNN(network, learning_rate=base_config['learning_rate'])\n",
    "    \n",
    "    # Train the model\n",
    "    history = model.fit(\n",
    "        X_train_ffnn, y_train_ffnn,\n",
    "        batch_size=base_config['batch_size'],\n",
    "        epochs=base_config['epochs'],\n",
    "        validation_data=(X_val, y_val),\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    # Store results\n",
    "    init_histories.append(history)\n",
    "    init_models.append(model)\n",
    "    \n",
    "    # Evaluate on test set\n",
    "    accuracy = evaluate_model(model, X_test, y_test_onehot)\n",
    "    init_accuracies.append(accuracy)\n",
    "    print(f\"Test accuracy: {accuracy:.4f}\")\n",
    "\n",
    "# Plot training loss\n",
    "plt.figure(figsize=(10, 5))\n",
    "for i, history in enumerate(init_histories):\n",
    "    plt.plot(history['train_loss'], label=f\"{initializer_names[i]}\")\n",
    "plt.title('Training Loss vs Weight Initialization')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()\n",
    "\n",
    "# Compare test accuracies\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.bar(initializer_names, init_accuracies)\n",
    "plt.title('Test Accuracy vs Weight Initialization')\n",
    "plt.xlabel('Initialization Method')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim(0, 1)\n",
    "plt.show()\n",
    "\n",
    "# Plot initial weight distributions\n",
    "plt.figure(figsize=(15, 5))\n",
    "for i, model in enumerate(init_models):\n",
    "    plt.subplot(1, len(init_models), i+1)\n",
    "    weights = model.network.weights[0].flatten()\n",
    "    plt.hist(weights, bins=30, alpha=0.7)\n",
    "    plt.title(f\"{initializer_names[i]} Weights\")\n",
    "    plt.xlabel(\"Weight Value\")\n",
    "    plt.ylabel(\"Frequency\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import sklearn's MLPClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "# Define architecture and parameters\n",
    "architecture = [784, 128, 10]\n",
    "learning_rate = 0.01\n",
    "batch_size = 32\n",
    "epochs = 5\n",
    "\n",
    "# Create our custom FFNN\n",
    "activations = [ReLU] + [Softmax]\n",
    "network = NeuralNetwork(\n",
    "    node_counts=architecture,\n",
    "    activations=activations,\n",
    "    loss_function=CCE(),\n",
    "    initialize_method=NormalInitializer(seed=42)\n",
    ")\n",
    "custom_model = FFNN(network, learning_rate=learning_rate)\n",
    "\n",
    "# Train our custom model\n",
    "print(\"Training custom FFNN model...\")\n",
    "custom_history = custom_model.fit(\n",
    "    X_train_ffnn, y_train_ffnn,\n",
    "    batch_size=batch_size,\n",
    "    epochs=epochs,\n",
    "    validation_data=(X_val, y_val),\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Create sklearn MLPClassifier\n",
    "sklearn_model = MLPClassifier(\n",
    "    hidden_layer_sizes=(128,),\n",
    "    activation='relu',\n",
    "    solver='sgd',\n",
    "    alpha=0.0001,\n",
    "    batch_size=batch_size,\n",
    "    learning_rate_init=learning_rate,\n",
    "    max_iter=epochs,\n",
    "    random_state=42,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "# Train sklearn model with correct target format\n",
    "print(\"\\nTraining sklearn MLPClassifier...\")\n",
    "# Convert string labels to integers if needed\n",
    "y_train_int = np.array(y_train).astype(int) if isinstance(y_train[0], str) else np.array(y_train, dtype=int)\n",
    "y_test_int = np.array(y_test).astype(int) if isinstance(y_test[0], str) else np.array(y_test, dtype=int)\n",
    "\n",
    "# Check first few labels to debug\n",
    "print(f\"First few training labels: {y_train_int[:5]}\")\n",
    "print(f\"Label type: {type(y_train_int)} {y_train_int.dtype}\")\n",
    "\n",
    "# Fit the model\n",
    "sklearn_model.fit(X_train, y_train_int)\n",
    "\n",
    "# Evaluate both models\n",
    "custom_accuracy = evaluate_model(custom_model, X_test, y_test_onehot)\n",
    "sklearn_predictions = sklearn_model.predict(X_test)\n",
    "sklearn_accuracy = np.mean(sklearn_predictions == y_test_int)\n",
    "\n",
    "print(\"\\nModel Comparison:\")\n",
    "print(f\"Custom FFNN accuracy: {custom_accuracy:.4f}\")\n",
    "print(f\"sklearn MLP accuracy: {sklearn_accuracy:.4f}\")\n",
    "\n",
    "# Compare accuracies\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.bar(['Custom FFNN', 'sklearn MLP'], [custom_accuracy, sklearn_accuracy])\n",
    "plt.title('Test Accuracy Comparison')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim(0, 1)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
