{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "os.chdir(\"../..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import custom FFNN implementation\n",
    "import os\n",
    "import sys\n",
    "# Add the parent directory to path to import your modules\n",
    "sys.path.append(os.path.dirname(os.path.dirname(os.getcwd())))\n",
    "\n",
    "from lib.neural import NeuralNetwork, NetworkLayer\n",
    "from lib.ffnn import FFNN\n",
    "from lib.activation import ReLU, Sigmoid, Tanh, Linear, Softmax\n",
    "from lib.loss import MSE, BCE, CCE\n",
    "from lib.weight_initializer import ZeroInitializer, UniformInitializer, NormalInitializer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Authors: The scikit-learn developers\n",
    "# SPDX-License-Identifier: BSD-3-Clause\n",
    "\n",
    "import time\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.utils import check_random_state\n",
    "import logging\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "# Turn down for faster convergence\n",
    "t0 = time.time()\n",
    "train_samples = 5000\n",
    "\n",
    "# Load data from https://www.openml.org/d/554\n",
    "logging.info(\"Loading data\")\n",
    "X, y = fetch_openml(\"mnist_784\", version=1, return_X_y=True, as_frame=False)\n",
    "\n",
    "random_state = check_random_state(0)\n",
    "permutation = random_state.permutation(X.shape[0])\n",
    "X = X[permutation]\n",
    "y = y[permutation]\n",
    "X = X.reshape((X.shape[0], -1))\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, train_size=train_samples, test_size=10000\n",
    ")\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Turn up tolerance for faster convergence\n",
    "clf = LogisticRegression(C=50.0 / train_samples, penalty=\"l1\", solver=\"saga\", tol=0.1)\n",
    "clf.fit(X_train, y_train)\n",
    "sparsity = np.mean(clf.coef_ == 0) * 100\n",
    "score = clf.score(X_test, y_test)\n",
    "# print('Best C % .4f' % clf.C_)\n",
    "print(\"Sparsity with L1 penalty: %.2f%%\" % sparsity)\n",
    "print(\"Test score with L1 penalty: %.4f\" % score)\n",
    "\n",
    "coef = clf.coef_.copy()\n",
    "plt.figure(figsize=(10, 5))\n",
    "scale = np.abs(coef).max()\n",
    "for i in range(10):\n",
    "    l1_plot = plt.subplot(2, 5, i + 1)\n",
    "    l1_plot.imshow(\n",
    "        coef[i].reshape(28, 28),\n",
    "        interpolation=\"nearest\",\n",
    "        cmap=plt.cm.RdBu,\n",
    "        vmin=-scale,\n",
    "        vmax=scale,\n",
    "    )\n",
    "    l1_plot.set_xticks(())\n",
    "    l1_plot.set_yticks(())\n",
    "    l1_plot.set_xlabel(\"Class %i\" % i)\n",
    "plt.suptitle(\"Classification vector for...\")\n",
    "\n",
    "run_time = time.time() - t0\n",
    "print(\"Example run in %.3f s\" % run_time)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess data for FFNN\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# Load data (using your already loaded data)\n",
    "# X_train and X_test are already loaded and scaled\n",
    "\n",
    "# Convert labels to one-hot encoding for neural network\n",
    "encoder = OneHotEncoder(sparse_output=False)\n",
    "y_train_onehot = encoder.fit_transform(y_train.reshape(-1, 1))\n",
    "y_test_onehot = encoder.transform(y_test.reshape(-1, 1))\n",
    "\n",
    "# Create validation set\n",
    "X_train_ffnn, X_val, y_train_ffnn, y_val = train_test_split(\n",
    "    X_train, y_train_onehot, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "print(f\"Training set: {X_train_ffnn.shape[0]} samples\")\n",
    "print(f\"Validation set: {X_val.shape[0]} samples\")\n",
    "print(f\"Test set: {X_test.shape[0]} samples\")\n",
    "print(f\"Input features: {X_train.shape[1]}\")\n",
    "print(f\"Output classes: {y_train_onehot.shape[1]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions for evaluation and visualization\n",
    "def evaluate_model(model, X, y_onehot):\n",
    "    \"\"\"Evaluate model accuracy on given data.\"\"\"\n",
    "    predictions = model.predict(X)\n",
    "    predicted_classes = np.argmax(predictions, axis=1)\n",
    "    true_classes = np.argmax(y_onehot, axis=1)\n",
    "    accuracy = np.mean(predicted_classes == true_classes)\n",
    "    return accuracy\n",
    "\n",
    "def plot_train_history(history, title=\"Training History\"):\n",
    "    \"\"\"Plot training and validation loss history.\"\"\"\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(history['train_loss'], label='Training Loss')\n",
    "    if 'val_loss' in history and history['val_loss']:\n",
    "        plt.plot(history['val_loss'], label='Validation Loss')\n",
    "    plt.title(title)\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_config = {\n",
    "    'learning_rate': 0.01,\n",
    "    'batch_size': 32,\n",
    "    'epochs': 5,  \n",
    "    'loss_function': CCE(),\n",
    "    'activation': Softmax(),\n",
    "    'initializer': NormalInitializer(seed=42)\n",
    "}\n",
    "\n",
    "# Define different architectures for width variation (fixed depth)\n",
    "width_variations = [\n",
    "    [784, 32, 10],         # Narrow\n",
    "    [784, 128, 10],        # Medium\n",
    "    [784, 512, 10]         # Wide\n",
    "]\n",
    "\n",
    "# Define different architectures for depth variation (fixed width)\n",
    "depth_variations = [\n",
    "    [784, 64, 10],               # Shallow (1 hidden layer)\n",
    "    [784, 64, 64, 10],           # Medium (2 hidden layers)\n",
    "    [784, 64, 64, 64, 10]        # Deep (3 hidden layers)\n",
    "]\n",
    "\n",
    "# Test width variations\n",
    "width_histories = []\n",
    "width_accuracies = []\n",
    "\n",
    "print(\"Testing width variations...\")\n",
    "for i, architecture in enumerate(width_variations):\n",
    "    print(f\"\\nWidth Variation {i+1}: {architecture}\")\n",
    "    \n",
    "    # Create activations list (output layer uses Softmax)\n",
    "    activations = [base_config['activation']] * (len(architecture) - 2) + [Softmax()]\n",
    "    \n",
    "    # Create neural network\n",
    "    network = NeuralNetwork(\n",
    "        node_counts=architecture,\n",
    "        activations=activations,\n",
    "        loss_function=base_config['loss_function'],\n",
    "        initialize_methods=base_config['initializer']\n",
    "    )\n",
    "    \n",
    "    # Create FFNN model\n",
    "    model = FFNN(network)\n",
    "    \n",
    "    # Train the model\n",
    "    history = model.fit(\n",
    "        X_train_ffnn, y_train_ffnn,\n",
    "        batch_size=base_config['batch_size'],\n",
    "        epochs=base_config['epochs'],\n",
    "        validation_data=(X_val, y_val),\n",
    "        learning_rate=base_config['learning_rate'],\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    # Store results\n",
    "    width_histories.append(history)\n",
    "    \n",
    "    # Evaluate on test set\n",
    "    accuracy = evaluate_model(model, X_test, y_test_onehot)\n",
    "    width_accuracies.append(accuracy)\n",
    "    print(f\"Test accuracy: {accuracy:.4f}\")\n",
    "\n",
    "# Plot results for width variations\n",
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "# Plot width variation loss\n",
    "plt.subplot(1, 2, 1)\n",
    "for i, history in enumerate(width_histories):\n",
    "    plt.plot(history['train_loss'], label=f\"Width {width_variations[i][1]}\")\n",
    "plt.title('Training Loss vs Width')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Compare test accuracies for width\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.bar([str(arch[1]) for arch in width_variations], width_accuracies)\n",
    "plt.title('Test Accuracy vs Width')\n",
    "plt.xlabel('Hidden Layer Width')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim(0, 1)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Test depth variations\n",
    "depth_histories = []\n",
    "depth_accuracies = []\n",
    "\n",
    "print(\"\\nTesting depth variations...\")\n",
    "for i, architecture in enumerate(depth_variations):\n",
    "    print(f\"\\nDepth Variation {i+1}: {architecture}\")\n",
    "    \n",
    "    # Create activations list (output layer uses Softmax)\n",
    "    activations = [base_config['activation']] * (len(architecture) - 2) + [Softmax()]\n",
    "    \n",
    "    # Create neural network\n",
    "    network = NeuralNetwork(\n",
    "        node_counts=architecture,\n",
    "        activations=activations,\n",
    "        loss_function=base_config['loss_function'],\n",
    "        initialize_methods=base_config['initializer']\n",
    "    )\n",
    "    \n",
    "    # Create FFNN model\n",
    "    model = FFNN(network)\n",
    "    \n",
    "    # Train the model\n",
    "    history = model.fit(\n",
    "        X_train_ffnn, y_train_ffnn,\n",
    "        batch_size=base_config['batch_size'],\n",
    "        epochs=base_config['epochs'],\n",
    "        validation_data=(X_val, y_val),\n",
    "        learning_rate=base_config['learning_rate'],\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    # Store results\n",
    "    depth_histories.append(history)\n",
    "    \n",
    "    # Evaluate on test set\n",
    "    accuracy = evaluate_model(model, X_test, y_test_onehot)\n",
    "    depth_accuracies.append(accuracy)\n",
    "    print(f\"Test accuracy: {accuracy:.4f}\")\n",
    "\n",
    "# Plot results for depth variations\n",
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "# Plot depth variation loss\n",
    "plt.subplot(1, 2, 1)\n",
    "for i, history in enumerate(depth_histories):\n",
    "    plt.plot(history['train_loss'], label=f\"Depth {len(depth_variations[i]) - 2}\")\n",
    "plt.title('Training Loss vs Depth')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Compare test accuracies for depth\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.bar([str(len(arch) - 2) for arch in depth_variations], depth_accuracies)\n",
    "plt.title('Test Accuracy vs Depth')\n",
    "plt.xlabel('Number of Hidden Layers')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim(0, 1)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define base architecture\n",
    "architecture = [784, 128, 10]\n",
    "\n",
    "# Define activation functions to test (for hidden layers)\n",
    "activation_functions = [Linear(), ReLU(), Sigmoid(), Tanh()]\n",
    "\n",
    "# Test different activation functions\n",
    "activation_histories = []\n",
    "activation_accuracies = []\n",
    "activation_models = []\n",
    "\n",
    "print(\"Testing activation functions...\")\n",
    "for activation in activation_functions:\n",
    "    print(f\"\\nActivation: {activation.__class__.__name__}\")\n",
    "    \n",
    "    # Create activations list (output layer uses Softmax)\n",
    "    activations = [activation] + [Softmax]\n",
    "    \n",
    "    # Create neural network\n",
    "    network = NeuralNetwork(\n",
    "        node_counts=architecture,\n",
    "        activations=activations,\n",
    "        loss_function=base_config['loss_function'],\n",
    "        initialize_methods=base_config['initializer']\n",
    "    )\n",
    "    \n",
    "    # Create FFNN model\n",
    "    model = FFNN(network)\n",
    "    \n",
    "    # Train the model\n",
    "    history = model.fit(\n",
    "        X_train_ffnn, y_train_ffnn,\n",
    "        batch_size=base_config['batch_size'],\n",
    "        epochs=base_config['epochs'],\n",
    "        validation_data=(X_val, y_val),\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    # Store results\n",
    "    activation_histories.append(history)\n",
    "    activation_models.append(model)\n",
    "    \n",
    "    # Evaluate on test set\n",
    "    accuracy = evaluate_model(model, X_test, y_test_onehot)\n",
    "    activation_accuracies.append(accuracy)\n",
    "    print(f\"Test accuracy: {accuracy:.4f}\")\n",
    "\n",
    "# Plot training loss\n",
    "plt.figure(figsize=(10, 5))\n",
    "for i, history in enumerate(activation_histories):\n",
    "    plt.plot(history['train_loss'], label=f\"{activation_functions[i].__class__.__name__}\")\n",
    "plt.title('Training Loss vs Activation Function')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()\n",
    "\n",
    "# Compare test accuracies\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.bar([act.__name__ for act in activation_functions], activation_accuracies)\n",
    "plt.title('Test Accuracy vs Activation Function')\n",
    "plt.xlabel('Activation Function')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim(0, 1)\n",
    "plt.show()\n",
    "\n",
    "# Plot weight distributions\n",
    "plt.figure(figsize=(15, 5))\n",
    "for i, model in enumerate(activation_models):\n",
    "    plt.subplot(1, len(activation_models), i+1)\n",
    "    weights = model.network.weights[0].flatten()\n",
    "    plt.hist(weights, bins=30, alpha=0.7)\n",
    "    plt.title(f\"{activation_functions[i].__name__} Weights\")\n",
    "    plt.xlabel(\"Weight Value\")\n",
    "    plt.ylabel(\"Frequency\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Plot gradient distributions\n",
    "plt.figure(figsize=(15, 5))\n",
    "for i, model in enumerate(activation_models):\n",
    "    plt.subplot(1, len(activation_models), i+1)\n",
    "    gradients = model.network.gradients[0].flatten()\n",
    "    plt.hist(gradients, bins=30, alpha=0.7)\n",
    "    plt.title(f\"{activation_functions[i].__name__} Gradients\")\n",
    "    plt.xlabel(\"Gradient Value\")\n",
    "    plt.ylabel(\"Frequency\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define base architecture\n",
    "architecture = [784, 128, 10]\n",
    "\n",
    "# Define learning rates to test\n",
    "learning_rates = [0.001, 0.01, 0.1]\n",
    "\n",
    "# Test different learning rates\n",
    "lr_histories = []\n",
    "lr_accuracies = []\n",
    "lr_models = []\n",
    "\n",
    "print(\"Testing learning rates...\")\n",
    "for lr in learning_rates:\n",
    "    print(f\"\\nLearning Rate: {lr}\")\n",
    "    \n",
    "    # Create activations list (output layer uses Softmax)\n",
    "    activations = [ReLU] + [Softmax]\n",
    "    \n",
    "    # Create neural network\n",
    "    network = NeuralNetwork(\n",
    "        node_counts=architecture,\n",
    "        activations=activations,\n",
    "        loss_function=base_config['loss_function'],\n",
    "        initialize_methods=base_config['initializer']\n",
    "    )\n",
    "    \n",
    "    # Create FFNN model\n",
    "    # model = FFNN(network, learning_rate=lr)\n",
    "    model = FFNN(network)\n",
    "    \n",
    "    # Train the model\n",
    "    history = model.fit(\n",
    "        X_train_ffnn, y_train_ffnn,\n",
    "        batch_size=base_config['batch_size'],\n",
    "        epochs=base_config['epochs'],\n",
    "        validation_data=(X_val, y_val),\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    # Store results\n",
    "    lr_histories.append(history)\n",
    "    lr_models.append(model)\n",
    "    \n",
    "    # Evaluate on test set\n",
    "    accuracy = evaluate_model(model, X_test, y_test_onehot)\n",
    "    lr_accuracies.append(accuracy)\n",
    "    print(f\"Test accuracy: {accuracy:.4f}\")\n",
    "\n",
    "# Plot training loss\n",
    "plt.figure(figsize=(10, 5))\n",
    "for i, history in enumerate(lr_histories):\n",
    "    plt.plot(history['train_loss'], label=f\"LR = {learning_rates[i]}\")\n",
    "plt.title('Training Loss vs Learning Rate')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()\n",
    "\n",
    "# Compare test accuracies\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.bar([str(lr) for lr in learning_rates], lr_accuracies)\n",
    "plt.title('Test Accuracy vs Learning Rate')\n",
    "plt.xlabel('Learning Rate')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim(0, 1)\n",
    "plt.show()\n",
    "\n",
    "# Plot weight distributions\n",
    "plt.figure(figsize=(15, 5))\n",
    "for i, model in enumerate(lr_models):\n",
    "    plt.subplot(1, len(lr_models), i+1)\n",
    "    weights = model.network.weights[0].flatten()\n",
    "    plt.hist(weights, bins=30, alpha=0.7)\n",
    "    plt.title(f\"LR = {learning_rates[i]} Weights\")\n",
    "    plt.xlabel(\"Weight Value\")\n",
    "    plt.ylabel(\"Frequency\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Plot gradient distributions\n",
    "plt.figure(figsize=(15, 5))\n",
    "for i, model in enumerate(lr_models):\n",
    "    plt.subplot(1, len(lr_models), i+1)\n",
    "    gradients = model.network.gradients[0].flatten()\n",
    "    plt.hist(gradients, bins=30, alpha=0.7)\n",
    "    plt.title(f\"LR = {learning_rates[i]} Gradients\")\n",
    "    plt.xlabel(\"Gradient Value\")\n",
    "    plt.ylabel(\"Frequency\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define base architecture\n",
    "architecture = [784, 128, 10]\n",
    "\n",
    "# Define initializers to test\n",
    "initializers = [\n",
    "    ZeroInitializer(),\n",
    "    UniformInitializer(low=-0.1, high=0.1, seed=42),\n",
    "    NormalInitializer(mean=0, var=0.1, seed=42)\n",
    "]\n",
    "initializer_names = [\"Zero\", \"Uniform\", \"Normal\"]\n",
    "\n",
    "# Test different initializers\n",
    "init_histories = []\n",
    "init_accuracies = []\n",
    "init_models = []\n",
    "\n",
    "print(\"Testing weight initializers...\")\n",
    "for i, initializer in enumerate(initializers):\n",
    "    print(f\"\\nInitializer: {initializer_names[i]}\")\n",
    "    \n",
    "    # Create activations list (output layer uses Softmax)\n",
    "    activations = [ReLU] + [Softmax]\n",
    "    \n",
    "    # Create neural network\n",
    "    network = NeuralNetwork(\n",
    "        node_counts=architecture,\n",
    "        activations=activations,\n",
    "        loss_function=base_config['loss_function'],\n",
    "        initialize_methods=initializer\n",
    "    )\n",
    "    \n",
    "    # Create FFNN model\n",
    "    # model = FFNN(network, learning_rate=base_config['learning_rate'])\n",
    "    model = FFNN(network)\n",
    "    \n",
    "    # Train the model\n",
    "    history = model.fit(\n",
    "        X_train_ffnn, y_train_ffnn,\n",
    "        batch_size=base_config['batch_size'],\n",
    "        epochs=base_config['epochs'],\n",
    "        validation_data=(X_val, y_val),\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    # Store results\n",
    "    init_histories.append(history)\n",
    "    init_models.append(model)\n",
    "    \n",
    "    # Evaluate on test set\n",
    "    accuracy = evaluate_model(model, X_test, y_test_onehot)\n",
    "    init_accuracies.append(accuracy)\n",
    "    print(f\"Test accuracy: {accuracy:.4f}\")\n",
    "\n",
    "# Plot training loss\n",
    "plt.figure(figsize=(10, 5))\n",
    "for i, history in enumerate(init_histories):\n",
    "    plt.plot(history['train_loss'], label=f\"{initializer_names[i]}\")\n",
    "plt.title('Training Loss vs Weight Initialization')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()\n",
    "\n",
    "# Compare test accuracies\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.bar(initializer_names, init_accuracies)\n",
    "plt.title('Test Accuracy vs Weight Initialization')\n",
    "plt.xlabel('Initialization Method')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim(0, 1)\n",
    "plt.show()\n",
    "\n",
    "# Plot initial weight distributions\n",
    "plt.figure(figsize=(15, 5))\n",
    "for i, model in enumerate(init_models):\n",
    "    plt.subplot(1, len(init_models), i+1)\n",
    "    weights = model.network.weights[0].flatten()\n",
    "    plt.hist(weights, bins=30, alpha=0.7)\n",
    "    plt.title(f\"{initializer_names[i]} Weights\")\n",
    "    plt.xlabel(\"Weight Value\")\n",
    "    plt.ylabel(\"Frequency\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import sklearn's MLPClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "# Define architecture and parameters\n",
    "architecture = [784, 128, 10]\n",
    "learning_rate = 0.01\n",
    "batch_size = 32\n",
    "epochs = 5\n",
    "\n",
    "# Create our custom FFNN\n",
    "activations = [ReLU] + [Softmax]\n",
    "network = NeuralNetwork(\n",
    "    node_counts=architecture,\n",
    "    activations=activations,\n",
    "    loss_function=CCE(),\n",
    "    initialize_methods=NormalInitializer(seed=42)\n",
    ")\n",
    "custom_model = FFNN(network)\n",
    "\n",
    "# Train our custom model\n",
    "print(\"Training custom FFNN model...\")\n",
    "custom_history = custom_model.fit(\n",
    "    X_train_ffnn, y_train_ffnn,\n",
    "    batch_size=batch_size,\n",
    "    epochs=epochs,\n",
    "    validation_data=(X_val, y_val),\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Create sklearn MLPClassifier\n",
    "sklearn_model = MLPClassifier(\n",
    "    hidden_layer_sizes=(128,),\n",
    "    activation='relu',\n",
    "    solver='sgd',\n",
    "    alpha=0.0001,\n",
    "    batch_size=batch_size,\n",
    "    learning_rate_init=learning_rate,\n",
    "    max_iter=epochs,\n",
    "    random_state=42,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "# Train sklearn model with correct target format\n",
    "print(\"\\nTraining sklearn MLPClassifier...\")\n",
    "# Convert string labels to integers if needed\n",
    "y_train_int = np.array(y_train).astype(int) if isinstance(y_train[0], str) else np.array(y_train, dtype=int)\n",
    "y_test_int = np.array(y_test).astype(int) if isinstance(y_test[0], str) else np.array(y_test, dtype=int)\n",
    "\n",
    "# Check first few labels to debug\n",
    "print(f\"First few training labels: {y_train_int[:5]}\")\n",
    "print(f\"Label type: {type(y_train_int)} {y_train_int.dtype}\")\n",
    "\n",
    "# Fit the model\n",
    "sklearn_model.fit(X_train, y_train_int)\n",
    "\n",
    "# Evaluate both models\n",
    "custom_accuracy = evaluate_model(custom_model, X_test, y_test_onehot)\n",
    "sklearn_predictions = sklearn_model.predict(X_test)\n",
    "sklearn_accuracy = np.mean(sklearn_predictions == y_test_int)\n",
    "\n",
    "print(\"\\nModel Comparison:\")\n",
    "print(f\"Custom FFNN accuracy: {custom_accuracy:.4f}\")\n",
    "print(f\"sklearn MLP accuracy: {sklearn_accuracy:.4f}\")\n",
    "\n",
    "# Compare accuracies\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.bar(['Custom FFNN', 'sklearn MLP'], [custom_accuracy, sklearn_accuracy])\n",
    "plt.title('Test Accuracy Comparison')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim(0, 1)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
