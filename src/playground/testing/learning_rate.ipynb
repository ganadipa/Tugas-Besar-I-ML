{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.utils import check_random_state\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# Add the parent directory to path to import your modules\n",
    "os.chdir(\"../..\")\n",
    "sys.path.append(os.path.dirname(os.path.dirname(os.getcwd())))\n",
    "from lib import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Authors: The scikit-learn developers\n",
    "# SPDX-License-Identifier: BSD-3-Clause\n",
    "\n",
    "# Turn down for faster convergence\n",
    "t0 = time.time()\n",
    "train_samples = 5000\n",
    "\n",
    "# Load data from https://www.openml.org/d/554\n",
    "X, y = fetch_openml(\"mnist_784\", version=1, return_X_y=True, as_frame=False)\n",
    "\n",
    "random_state = check_random_state(0)\n",
    "permutation = random_state.permutation(X.shape[0])\n",
    "X = X[permutation]\n",
    "y = y[permutation]\n",
    "X = X.reshape((X.shape[0], -1))\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, train_size=train_samples, test_size=10000\n",
    ")\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Turn up tolerance for faster convergence\n",
    "clf = LogisticRegression(C=50.0 / train_samples, penalty=\"l1\", solver=\"saga\", tol=0.1)\n",
    "clf.fit(X_train, y_train)\n",
    "sparsity = np.mean(clf.coef_ == 0) * 100\n",
    "score = clf.score(X_test, y_test)\n",
    "# print('Best C % .4f' % clf.C_)\n",
    "print(\"Sparsity with L1 penalty: %.2f%%\" % sparsity)\n",
    "print(\"Test score with L1 penalty: %.4f\" % score)\n",
    "\n",
    "coef = clf.coef_.copy()\n",
    "plt.figure(figsize=(10, 5))\n",
    "scale = np.abs(coef).max()\n",
    "for i in range(10):\n",
    "    l1_plot = plt.subplot(2, 5, i + 1)\n",
    "    l1_plot.imshow(\n",
    "        coef[i].reshape(28, 28),\n",
    "        interpolation=\"nearest\",\n",
    "        cmap=plt.cm.RdBu,\n",
    "        vmin=-scale,\n",
    "        vmax=scale,\n",
    "    )\n",
    "    l1_plot.set_xticks(())\n",
    "    l1_plot.set_yticks(())\n",
    "    l1_plot.set_xlabel(\"Class %i\" % i)\n",
    "plt.suptitle(\"Classification vector for...\")\n",
    "\n",
    "run_time = time.time() - t0\n",
    "print(\"Example run in %.3f s\" % run_time)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert labels to one-hot encoding for neural network\n",
    "encoder = OneHotEncoder(sparse_output=False)\n",
    "y_train_onehot = encoder.fit_transform(y_train.reshape(-1, 1))\n",
    "y_test_onehot = encoder.transform(y_test.reshape(-1, 1))\n",
    "\n",
    "# Create validation set\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_train, y_train_onehot, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Print dataset information\n",
    "print(f\"Training set: {X_train.shape[0]} samples\")\n",
    "print(f\"Validation set: {X_val.shape[0]} samples\")\n",
    "print(f\"Test set: {X_test.shape[0]} samples\")\n",
    "print(f\"Input features: {X_train.shape[1]}\")\n",
    "print(f\"Output classes: {y_train_onehot.shape[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pengaruh Learning Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define depth\n",
    "depth_variations = [\n",
    "    [784, 156, 156, 10]\n",
    "]\n",
    "\n",
    "# Define activation functions\n",
    "activation_variations = [\n",
    "    [ReLU(), ReLU(), Softmax()]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Neural Network\n",
    "per_sepuluh_network = NeuralNetwork(\n",
    "    node_counts = depth_variations[0],\n",
    "    activations = activation_variations[0],\n",
    "    loss_function = CCE(),\n",
    "    initialize_methods = NormalInitializer(seed=22)\n",
    ")\n",
    "\n",
    "per_seratus_network = NeuralNetwork(\n",
    "    node_counts = depth_variations[0],\n",
    "    activations = activation_variations[0],\n",
    "    loss_function = CCE(),\n",
    "    initialize_methods = NormalInitializer(seed=22)\n",
    ")\n",
    "\n",
    "per_seribu_network = NeuralNetwork(\n",
    "    node_counts = depth_variations[0],\n",
    "    activations = activation_variations[0],\n",
    "    loss_function = CCE(),\n",
    "    initialize_methods = NormalInitializer(seed=22)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create FFNN model\n",
    "ffnn_per_sepuluh = FFNN(per_sepuluh_network)\n",
    "\n",
    "ffnn_per_seratus = FFNN(per_seratus_network)\n",
    "\n",
    "ffnn_per_seribu = FFNN(per_seribu_network)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "per_sepuluh_history = ffnn_per_sepuluh.fit(\n",
    "    x_train=X_train,\n",
    "    y_train=y_train,\n",
    "    batch_size=32,\n",
    "    epochs=20,\n",
    "    validation_data=(X_val, y_val),\n",
    "    learning_rate=0.1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "per_seratus_history = ffnn_per_seratus.fit(\n",
    "    x_train=X_train,\n",
    "    y_train=y_train,\n",
    "    batch_size=32,\n",
    "    epochs=20,\n",
    "    validation_data=(X_val, y_val),\n",
    "    learning_rate=0.01,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "per_seribu_history = ffnn_per_seribu.fit(\n",
    "    x_train=X_train,\n",
    "    y_train=y_train,\n",
    "    batch_size=32,\n",
    "    epochs=20,\n",
    "    validation_data=(X_val, y_val),\n",
    "    learning_rate=0.001,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model\n",
    "evaluate_model(ffnn_per_sepuluh, X_test, y_test_onehot)\n",
    "\n",
    "evaluate_model(ffnn_per_seratus, X_test, y_test_onehot)\n",
    "\n",
    "evaluate_model(ffnn_per_seribu, X_test, y_test_onehot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the training history\n",
    "plot_training_loss(per_sepuluh_history, \"0.1 LR Training History\")\n",
    "\n",
    "plot_training_loss(per_seratus_history, \"0.01 LR Training History\")\n",
    "\n",
    "plot_training_loss(per_seribu_history, \"0.001 LR Training History\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Weights\n",
    "ffnn_per_sepuluh.plot_weights(title=\"FFNN 0.1 LR Weights\")\n",
    "\n",
    "ffnn_per_seratus.plot_weights(title=\"FFNN 0.01 LR Weights\")\n",
    "\n",
    "ffnn_per_seribu.plot_weights(title=\"FFNN 0.001 LR Weights\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Gradient of Weights\n",
    "ffnn_per_sepuluh.plot_gradients(title=\"FFNN 0.1 LR Gradients\")\n",
    "\n",
    "ffnn_per_seratus.plot_gradients(title=\"FFNN 0.01 LR Gradients\")\n",
    "\n",
    "ffnn_per_seribu.plot_gradients(title=\"FFNN 0.001 LR Gradients\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
